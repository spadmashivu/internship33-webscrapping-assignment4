{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613e4e47",
   "metadata": {},
   "source": [
    "# webscrapping assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81073a2f",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20cb25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import  library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c1153e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89410940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50307604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Sr no\n",
    "sr=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tr/td[1]')\n",
    "\n",
    "for name in names[:30]:\n",
    "\n",
    "    sr.append(name.text)\n",
    "sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79cdceea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Shape of You\"[15]',\n",
       " '\"Bath Song\"[17]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Uptown Funk\"[24]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[25]',\n",
       " '\"Wheels on the Bus\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Sugar\"[34]',\n",
       " '\"Roar\"[35]',\n",
       " '\"Counting Stars\"[36]',\n",
       " '\"Axel F\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Dark Horse\"[41]',\n",
       " '\"Faded\"[42]',\n",
       " '\"Girls Like You\"[43]',\n",
       " '\"Let Her Go\"[44]',\n",
       " '\"Waka Waka (This Time for Africa)\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Bailando\"[47]',\n",
       " '\"Lean On\"[48]',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " '\"Shake It Off\"[50]']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Video Name\n",
    "video=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tr/td[2]')\n",
    "\n",
    "for name in names[:30]:\n",
    "\n",
    "    video.append(name.text)\n",
    "video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e7310bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Crazy Frog',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Maroon 5',\n",
       " 'Passenger',\n",
       " 'Shakira',\n",
       " 'Ed Sheeran',\n",
       " 'Enrique Iglesias',\n",
       " 'Major Lazer',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " 'Taylor Swift']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Video Artist\n",
    "uploader=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tr/td[3]')\n",
    "\n",
    "for name in names[:30]:\n",
    "\n",
    "    uploader.append(name.text)\n",
    "uploader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19ca0474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11.83',\n",
       " '8.02',\n",
       " '6.54',\n",
       " '5.86',\n",
       " '5.81',\n",
       " '5.71',\n",
       " '5.04',\n",
       " '4.77',\n",
       " '4.74',\n",
       " '4.69',\n",
       " '4.62',\n",
       " '4.52',\n",
       " '4.15',\n",
       " '3.79',\n",
       " '3.69',\n",
       " '3.69',\n",
       " '3.63',\n",
       " '3.61',\n",
       " '3.52',\n",
       " '3.44',\n",
       " '3.40',\n",
       " '3.38',\n",
       " '3.35',\n",
       " '3.35',\n",
       " '3.34',\n",
       " '3.31',\n",
       " '3.30',\n",
       " '3.29',\n",
       " '3.24',\n",
       " '3.23']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Video Views\n",
    "views=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tr/td[4]')\n",
    "\n",
    "for name in names[:30]:\n",
    "\n",
    "    views.append(name.text)\n",
    "views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06b01ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'May 2, 2018',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'May 24, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'June 16, 2009',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'June 25, 2018',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'July 25, 2012',\n",
       " 'June 4, 2010',\n",
       " 'November 9, 2017',\n",
       " 'April 11, 2014',\n",
       " 'March 22, 2015',\n",
       " 'January 26, 2018',\n",
       " 'August 18, 2014']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Video Date\n",
    "up_date=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//tr/td[5]')\n",
    "\n",
    "for name in names[:30]:\n",
    "\n",
    "    up_date.append(name.text)\n",
    "up_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba4a7a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                               \"Shape of You\"[15]   \n",
       "4    5.                                  \"Bath Song\"[17]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9   10.                          \"Wheels on the Bus\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.                                      \"Faded\"[42]   \n",
       "22  23.                             \"Girls Like You\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.83  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.02  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.54  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.86  \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   5.81  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.71  \n",
       "6                                       ChuChu TV      March 6, 2014   5.04  \n",
       "7                                     Mark Ronson  November 19, 2014   4.77  \n",
       "8                                     Miroshka TV  February 27, 2018   4.74  \n",
       "9                      Cocomelon – Nursery Rhymes       May 24, 2018   4.69  \n",
       "10                                            Psy      July 15, 2012   4.62  \n",
       "11                                     Get Movies   January 31, 2012   4.52  \n",
       "12                                      El Chombo      April 5, 2018   4.15  \n",
       "13                                       Maroon 5   January 14, 2015   3.79  \n",
       "14                                     Katy Perry  September 5, 2013   3.69  \n",
       "15                                    OneRepublic       May 31, 2013   3.69  \n",
       "16                                     Crazy Frog      June 16, 2009   3.63  \n",
       "17                                  Justin Bieber   October 22, 2015   3.61  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.52  \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   3.44  \n",
       "20                                     Katy Perry  February 20, 2014   3.40  \n",
       "21                                    Alan Walker   December 3, 2015   3.38  \n",
       "22                                       Maroon 5       May 31, 2018   3.35  \n",
       "23                                      Passenger      July 25, 2012   3.35  \n",
       "24                                        Shakira       June 4, 2010   3.34  \n",
       "25                                     Ed Sheeran   November 9, 2017   3.31  \n",
       "26                               Enrique Iglesias     April 11, 2014   3.30  \n",
       "27                                    Major Lazer     March 22, 2015   3.29  \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.24  \n",
       "29                                   Taylor Swift    August 18, 2014   3.23  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Rank':sr,'Name':video,'Artist':uploader,'Upload Date':up_date,'Views':views})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bf2e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97fab4f",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e3b9a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8a9d6843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3d4ad524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8a024f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B680+571008]\n\tOrdinal0 [0x00C3BBD6+768982]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [225]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[0;32m      2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/nav/div[1]/div[2]/ul[1]/li[2]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msearch_btn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B680+571008]\n\tOrdinal0 [0x00C3BBD6+768982]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0463df89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <div class=\"cSBDisplay ng-binding\" ng-click=\"cSBShowList($event)\">...</div> is not clickable at point (332, 18). Other element would receive the click: <img src=\"https://www.bcci.tv/assets/images/logo.png\" class=\"img-fluid\" alt=\"logo\">\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [226]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[0;32m      2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[1]/div/div[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msearch_btn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <div class=\"cSBDisplay ng-binding\" ng-click=\"cSBShowList($event)\">...</div> is not clickable at point (332, 18). Other element would receive the click: <img src=\"https://www.bcci.tv/assets/images/logo.png\" class=\"img-fluid\" alt=\"logo\">\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[1]/div/div[1]')\n",
    "search_btn.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5ccce38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [227]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:856\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    854\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]')\n",
    "search_btn.click()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "574e9fe2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:856\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    854\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[2]/div/div[1]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24004a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341aa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0589967f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37eb1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008281cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8bc08f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping ODI matches\n",
    "views=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-mid d-flex align-items-center justify-content-between\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    views.append(name.text.split('\\n'))\n",
    "views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "67f2bee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "955bf674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping ODI matches Dates\n",
    "up_date=[]\n",
    "names = driver.find_elements(By.XPATH,'//h5[@class=\"fix-text\"][2]/span')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    up_date.append(name.text)\n",
    "up_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08a72e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(up_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0806f89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping ODI matches Places\n",
    "place=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    place.append(name.text)\n",
    "place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20174a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3 JAN 2023'],\n",
       " ['5 JAN 2023'],\n",
       " ['7 JAN 2023'],\n",
       " ['10 JAN 2023'],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " [''],\n",
       " ['']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping ODI matches Date\n",
    "date=[]\n",
    "names = driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    date.append(name.text.split('\\n'))\n",
    "date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "467826ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2864bfe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping ODI matches time\n",
    "time=[]\n",
    "names = driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    time.append(name.text.split('\\n'))\n",
    "time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2e3f68ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [236]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#creating dataframe \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m DF\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMatch Title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mviews\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSeries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mup_date\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mplace\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m DF\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Match Title':views,'Series':up_date,'Place':place,'Date':date,'Time':time})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d1d13980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cc541",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1d991752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2a95d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://www.guru99.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe89ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cda883fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a/strong')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76680908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. ElementNotVisibleException',\n",
       " '2. ElementNotSelectableException',\n",
       " '3. NoSuchElementException',\n",
       " '4. NoSuchFrameException',\n",
       " '5. NoAlertPresentException',\n",
       " '6. NoSuchWindowException',\n",
       " '7. StaleElementReferenceException',\n",
       " '8. SessionNotFoundException',\n",
       " '9. TimeoutException',\n",
       " '10. WebDriverException',\n",
       " '11. ConnectionClosedException',\n",
       " '12. ElementClickInterceptedException',\n",
       " '13. ElementNotInteractableException',\n",
       " '14. ErrorInResponseException',\n",
       " '15. ErrorHandler.UnknownServerException',\n",
       " '16. ImeActivationFailedException',\n",
       " '17. ImeNotAvailableException',\n",
       " '18. InsecureCertificateException',\n",
       " '19. InvalidArgumentException',\n",
       " '20. InvalidCookieDomainException',\n",
       " '21. InvalidCoordinatesException',\n",
       " '22. InvalidElementStateException',\n",
       " '23. InvalidSessionIdException',\n",
       " '24. InvalidSwitchToTargetException',\n",
       " '25. JavascriptException',\n",
       " '26. JsonException',\n",
       " '27. NoSuchAttributeException',\n",
       " '28. MoveTargetOutOfBoundsException',\n",
       " '29. NoSuchContextException',\n",
       " '30. NoSuchCookieException',\n",
       " '31. NotFoundException',\n",
       " '32. RemoteDriverServerException',\n",
       " '33. ScreenshotException',\n",
       " '34. SessionNotCreatedException',\n",
       " '35. UnableToSetCookieException',\n",
       " '36. UnexpectedTagNameException',\n",
       " '37. UnhandledAlertException',\n",
       " '38. UnexpectedAlertPresentException',\n",
       " '39. UnknownMethodException',\n",
       " '40. UnreachableBrowserException',\n",
       " '41. UnsupportedCommandException']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Exception Names\n",
    "title=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"entry-content single-content\"]/p')\n",
    "\n",
    "for name in names[:41]:\n",
    "\n",
    "    title.append(name.text.split(',')[0].split(':')[0])\n",
    "title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6bef2e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       " ' This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       " ' This Exception occurs if an element could not be found.',\n",
       " ' This Exception occurs if the frame target to be switched to does not exist.',\n",
       " ' This Exception occurs when you switch to no presented alert.',\n",
       " ' This Exception occurs if the window target to be switch does not exist.',\n",
       " ' This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       " ' The WebDriver is acting after you quit the browser.',\n",
       " ' Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn’t found in the specified time.',\n",
       " ' This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       " ' This type of Exception takes place when there is a disconnection in the driver.',\n",
       " ' The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       " ' This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       " ' This happens while interacting with the Firefox extension or the remote driver server.',\n",
       " ' Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       " ' This expectation will occur when IME engine activation has failed.',\n",
       " ' It takes place when IME support is unavailable.',\n",
       " ' Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       " ' It occurs when an argument does not belong to the expected type.',\n",
       " ' This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       " ' This type of Exception matches an interacting operation that is not valid.',\n",
       " ' It occurs when command can’t be finished when the element is invalid.',\n",
       " ' This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       " ' This occurs when the frame or window target to be switched does not exist.',\n",
       " ' This issue occurs while executing JavaScript given by the user.',\n",
       " ' It occurs when you afford to get the session when the session is not created.',\n",
       " ' This kind of Exception occurs when the attribute of an element could not be found.',\n",
       " ' It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       " ' ContextAware does mobile device testing.',\n",
       " ' This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       " ' This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       " ' This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       " ' It is not possible to capture a screen.',\n",
       " ' It happens when a new session could not be successfully created.',\n",
       " ' This occurs if a driver is unable to set a cookie.',\n",
       " ' Happens if a support class did not get a web element as expected.',\n",
       " ' This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       " ' It occurs when there is the appearance of an unexpected alert.',\n",
       " ' This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       " ' This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       " ' This occurs when remote WebDriver doesn’t send valid commands as expected.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Exception Description\n",
    "titles=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"entry-content single-content\"]/p')\n",
    "\n",
    "for name in names[:41]:\n",
    "\n",
    "    titles.append(name.text.split(':')[1])\n",
    "titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "605f42f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. InvalidElementStateException</td>\n",
       "      <td>It occurs when command can’t be finished when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. JsonException</td>\n",
       "      <td>It occurs when you afford to get the session ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an aler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver doesn’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       NAME  \\\n",
       "0             1. ElementNotVisibleException   \n",
       "1          2. ElementNotSelectableException   \n",
       "2                 3. NoSuchElementException   \n",
       "3                   4. NoSuchFrameException   \n",
       "4                5. NoAlertPresentException   \n",
       "5                  6. NoSuchWindowException   \n",
       "6         7. StaleElementReferenceException   \n",
       "7               8. SessionNotFoundException   \n",
       "8                       9. TimeoutException   \n",
       "9                    10. WebDriverException   \n",
       "10            11. ConnectionClosedException   \n",
       "11     12. ElementClickInterceptedException   \n",
       "12      13. ElementNotInteractableException   \n",
       "13             14. ErrorInResponseException   \n",
       "14  15. ErrorHandler.UnknownServerException   \n",
       "15         16. ImeActivationFailedException   \n",
       "16             17. ImeNotAvailableException   \n",
       "17         18. InsecureCertificateException   \n",
       "18             19. InvalidArgumentException   \n",
       "19         20. InvalidCookieDomainException   \n",
       "20          21. InvalidCoordinatesException   \n",
       "21         22. InvalidElementStateException   \n",
       "22            23. InvalidSessionIdException   \n",
       "23       24. InvalidSwitchToTargetException   \n",
       "24                  25. JavascriptException   \n",
       "25                        26. JsonException   \n",
       "26             27. NoSuchAttributeException   \n",
       "27       28. MoveTargetOutOfBoundsException   \n",
       "28               29. NoSuchContextException   \n",
       "29                30. NoSuchCookieException   \n",
       "30                    31. NotFoundException   \n",
       "31          32. RemoteDriverServerException   \n",
       "32                  33. ScreenshotException   \n",
       "33           34. SessionNotCreatedException   \n",
       "34           35. UnableToSetCookieException   \n",
       "35           36. UnexpectedTagNameException   \n",
       "36              37. UnhandledAlertException   \n",
       "37      38. UnexpectedAlertPresentException   \n",
       "38               39. UnknownMethodException   \n",
       "39          40. UnreachableBrowserException   \n",
       "40          41. UnsupportedCommandException   \n",
       "\n",
       "                                          DESCRIPTION  \n",
       "0    This type of Selenium exception occurs when a...  \n",
       "1    This Selenium exception occurs when an elemen...  \n",
       "2    This Exception occurs if an element could not...  \n",
       "3    This Exception occurs if the frame target to ...  \n",
       "4    This Exception occurs when you switch to no p...  \n",
       "5    This Exception occurs if the window target to...  \n",
       "6    This Selenium exception occurs happens when t...  \n",
       "7    The WebDriver is acting after you quit the br...  \n",
       "8    Thrown when there is not enough time for a co...  \n",
       "9    This Exception takes place when the WebDriver...  \n",
       "10   This type of Exception takes place when there...  \n",
       "11   The command may not be completed as the eleme...  \n",
       "12   This Selenium exception is thrown when any el...  \n",
       "13   This happens while interacting with the Firef...  \n",
       "14   Exception is used as a placeholder in case if...  \n",
       "15   This expectation will occur when IME engine a...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17   Navigation made the user agent to hit a certi...  \n",
       "18   It occurs when an argument does not belong to...  \n",
       "19   This happens when you try to add a cookie und...  \n",
       "20   This type of Exception matches an interacting...  \n",
       "21   It occurs when command can’t be finished when...  \n",
       "22   This Exception took place when the given sess...  \n",
       "23   This occurs when the frame or window target t...  \n",
       "24   This issue occurs while executing JavaScript ...  \n",
       "25   It occurs when you afford to get the session ...  \n",
       "26   This kind of Exception occurs when the attrib...  \n",
       "27   It takes place if the target provided to the ...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29   This Exception occurs when no cookie matching...  \n",
       "30   This Exception is a subclass of WebDriverExce...  \n",
       "31   This Selenium exception is thrown when the se...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33   It happens when a new session could not be su...  \n",
       "34   This occurs if a driver is unable to set a co...  \n",
       "35   Happens if a support class did not get a web ...  \n",
       "36   This expectation occurs when there is an aler...  \n",
       "37   It occurs when there is the appearance of an ...  \n",
       "38   This Exception happens when the requested com...  \n",
       "39   This Exception occurs only when the browser i...  \n",
       "40   This occurs when remote WebDriver doesn’t sen...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'NAME':title,'DESCRIPTION':titles})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f06e3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c23c5",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1acad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a6188c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import nec library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc4a2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c062e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4c26a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec3c37bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <a href=\"economy/india-statistics.php\">...</a> is not clickable at point (399, 126). Other element would receive the click: <span id=\"cookieconsent:desc\" class=\"cc-message\">...</span>\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[0;32m      2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msearch_btn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <a href=\"economy/india-statistics.php\">...</a> is not clickable at point (399, 126). Other element would receive the click: <span id=\"cookieconsent:desc\" class=\"cc-message\">...</span>\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f14bc3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [107]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:856\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    854\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b34b6760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Sr NO\n",
    "number=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[1]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    number.append(name.text)\n",
    "number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca57d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping States\n",
    "state=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[2]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    state.append(name.text)\n",
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c429a24b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping GSDP 18-19\n",
    "GSDP1819=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[3]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    GSDP1819.append(name.text)\n",
    "GSDP1819\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5fd52200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GSDP1819)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f092cebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping GSDP 19-20\n",
    "GSDP1920=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[4]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    GSDP1920.append(name.text)\n",
    "GSDP1920\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8527e029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Share 18-19\n",
    "share1819=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[5]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    share1819.append(name.text)\n",
    "share1819\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b36b9f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.471',\n",
       " '15.388',\n",
       " '96.611',\n",
       " '425.549',\n",
       " '64.403',\n",
       " '7.997',\n",
       " '15.674',\n",
       " '13.761',\n",
       " '363.245',\n",
       " '323.057',\n",
       " '835.351',\n",
       " '81.257',\n",
       " '668.156',\n",
       " '0.477',\n",
       " '343.114',\n",
       " '14,866.740',\n",
       " '61.231',\n",
       " '17.378',\n",
       " '719.919',\n",
       " '7.586',\n",
       " '48.707',\n",
       " '59.928',\n",
       " '24.681',\n",
       " '12.003',\n",
       " '0.055',\n",
       " '3.440',\n",
       " '2.387',\n",
       " '11.847',\n",
       " '0.114',\n",
       " '0.499',\n",
       " '68.498',\n",
       " '1.862',\n",
       " '102.427']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping GDP\n",
    "GDP=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"dataTables_wrapper\"][1]/table//tbody/tr/td[6]')\n",
    "\n",
    "for name in names[:33]:\n",
    "\n",
    "    GDP.append(name.text)\n",
    "GDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6f58fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [102]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#creating dataframe \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m DF\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGSDP(18-19)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mGSDP1819\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGSDP(19-20)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mGSDP1920\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShare(18-19)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mshare1819\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGDP($ billion)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mGDP\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m DF\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Rank':number,'State':state,'GSDP(18-19)':GSDP1819,'GSDP(19-20)':GSDP1920,'Share(18-19)':share1819,'GDP($ billion)':GDP})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "53185628",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852e1d9",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "752f1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import nec library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e4d6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38f8e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3d369cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[5]/div/div/div/div/div/main/div[2]/div/div/turbo-frame/tab-container/div[2]/div[1]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[1]/div[5]/div/div/div/div/div/main/div[2]/div/div/turbo-frame/tab-container/div[2]/div[1]/a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:856\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    854\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[5]/div/div/div/div/div/main/div[2]/div/div/turbo-frame/tab-container/div[2]/div[1]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/div/div/div/div/div/main/div[2]/div/div/turbo-frame/tab-container/div[2]/div[1]/a')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bdc93e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[5]/main/div[2]/div/div/div[3]/div[1]/div[3]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [112]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/html/body/div[1]/div[5]/main/div[2]/div/div/div[3]/div[1]/div[3]/a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:856\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    853\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    854\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div[5]/main/div[2]/div/div/div[3]/div[1]/div[3]/a\"}\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C3AC2F+764975]\n\tOrdinal0 [0x00C3AE1B+765467]\n\tOrdinal0 [0x00C6D0F2+970994]\n\tOrdinal0 [0x00C57364+881508]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/main/div[2]/div/div/div[3]/div[1]/div[3]/a')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c6f6f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#URLs of the trending Github\n",
    "product_URL = []\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]//a')\n",
    "    for i in url:\n",
    "        product_URL.append(i.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "feb0bd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "918ddf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9ace78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the trending Github Description\n",
    "disc=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[1]/div/p')\n",
    "        disc.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        disc.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4d66c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aa687a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "693acd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the trending Github Titles\n",
    "title=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/div/main/div/div[1]/div/div/span[1]/a')\n",
    "        title.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        title.append('-')\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4fca821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce00a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b62c284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the trending Github Contributors count\n",
    "con=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[4]/div/h2/a/span')\n",
    "        con.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        con.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cdbaa978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4d13107c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6f8fadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of the trending Github Language\n",
    "Lan=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/div[5]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/ul/li/a/span[1]')\n",
    "        Lan.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Lan.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bc0f579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3cb36f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fdda58f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "      <th>Repository URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Repository title, Repository description, Contributors count, Language used, Repository URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Repository title':title,'Repository description':disc,'Contributors count':con,'Language used':Lan,'Repository URL':product_URL})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "710bb66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8430c",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "92d8c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import nec library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c385710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect webdriver\n",
    "\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a4030c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://www.billboard.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ed89d79f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element is not clickable at point (154, 1220)\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# click button\u001b[39;00m\n\u001b[0;32m      2\u001b[0m search_btn\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/html/body/div[3]/main/div[2]/div[1]/div[1]/div[1]/div[2]/div/div[2]/a[1]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msearch_btn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:88\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:396\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    395\u001b[0m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element is not clickable at point (154, 1220)\n  (Session info: chrome=108.0.5359.73)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B7BD+571325]\n\tOrdinal0 [0x00C41499+791705]\n\tOrdinal0 [0x00C3F4AC+783532]\n\tOrdinal0 [0x00C3D0AB+774315]\n\tOrdinal0 [0x00C3BD37+769335]\n\tOrdinal0 [0x00C31C76+728182]\n\tOrdinal0 [0x00C5731C+881436]\n\tOrdinal0 [0x00C315BF+726463]\n\tOrdinal0 [0x00C57534+881972]\n\tOrdinal0 [0x00C6B56A+963946]\n\tOrdinal0 [0x00C57136+880950]\n\tOrdinal0 [0x00C2FEFD+720637]\n\tOrdinal0 [0x00C30F3F+724799]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00D1B128+1683752]\n\tOrdinal0 [0x00D1B215+1683989]\n\tOrdinal0 [0x00D26484+1729668]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "# click button\n",
    "search_btn=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div[1]/div[2]/div/div[2]/a[1]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1a4033b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping top 100 Song Names\n",
    "songname=[]\n",
    "names = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "\n",
    "for name in names[:100]:\n",
    "\n",
    "    songname.append(name.text.split('\\n')[0])\n",
    "songname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "03c88b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping top 100 Song Artist\n",
    "artist=[]\n",
    "names = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "\n",
    "for name in names[:100]:\n",
    "\n",
    "    artist.append(name.text.split('\\n')[1])\n",
    "artist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "572c73b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping top 100 Song lastweek Rank\n",
    "lastweek=[]\n",
    "names = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "\n",
    "for name in names[:100]:\n",
    "\n",
    "    lastweek.append(name.text.split('\\n')[2])\n",
    "lastweek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba5aad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping top 100 Song peakweek Rank\n",
    "peak=[]\n",
    "names = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "\n",
    "for name in names[:100]:\n",
    "\n",
    "    peak.append(name.text.split('\\n')[3])\n",
    "peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "381ce752",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B680+571008]\n\tOrdinal0 [0x00C2F924+719140]\n\tOrdinal0 [0x00C57210+881168]\n\tOrdinal0 [0x00C53FAF+868271]\n\tOrdinal0 [0x00C53AF8+867064]\n\tOrdinal0 [0x00BEA257+434775]\n\tOrdinal0 [0x00BEA8F3+436467]\n\tOrdinal0 [0x00BEAD2A+437546]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00BEA0C7+434375]\n\tOrdinal0 [0x00BE9AD2+432850]\n\tGetHandleVerifier [0x0104D12C+2893020]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Scrapping top 100 Song Weeks on board\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m names \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//ul[@class=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names[:\u001b[38;5;241m100\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     weeks\u001b[38;5;241m.\u001b[39mappend(name\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m4\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:889\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    885\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[0;32m    887\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    431\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00D7ACD3+2075859]\n\tOrdinal0 [0x00D0EE61+1633889]\n\tOrdinal0 [0x00C0B680+571008]\n\tOrdinal0 [0x00C2F924+719140]\n\tOrdinal0 [0x00C57210+881168]\n\tOrdinal0 [0x00C53FAF+868271]\n\tOrdinal0 [0x00C53AF8+867064]\n\tOrdinal0 [0x00BEA257+434775]\n\tOrdinal0 [0x00BEA8F3+436467]\n\tOrdinal0 [0x00BEAD2A+437546]\n\tGetHandleVerifier [0x0102EED2+2769538]\n\tGetHandleVerifier [0x01020D95+2711877]\n\tGetHandleVerifier [0x00E0A03A+521194]\n\tGetHandleVerifier [0x00E08DA0+516432]\n\tOrdinal0 [0x00D1682C+1665068]\n\tOrdinal0 [0x00BEA0C7+434375]\n\tOrdinal0 [0x00BE9AD2+432850]\n\tGetHandleVerifier [0x0104D12C+2893020]\n\tBaseThreadInitThunk [0x76656939+25]\n\tRtlGetFullPathName_UEx [0x775B8FD2+1218]\n\tRtlGetFullPathName_UEx [0x775B8F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "#Scrapping top 100 Song Weeks on board\n",
    "names = driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')\n",
    "\n",
    "for name in names[:100]:\n",
    "\n",
    "    weeks.append(name.text.split('\\n')[4])\n",
    "weeks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7b8ae7ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weeks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#creating dataframe \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m DF\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSong Name\u001b[39m\u001b[38;5;124m'\u001b[39m:songname,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArtist Name\u001b[39m\u001b[38;5;124m'\u001b[39m:artist,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Week Rank\u001b[39m\u001b[38;5;124m'\u001b[39m:lastweek,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeak Rank\u001b[39m\u001b[38;5;124m'\u001b[39m:peak,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeeks on board\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mweeks\u001b[49m})\n\u001b[0;32m      4\u001b[0m DF\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weeks' is not defined"
     ]
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Song Name':songname,'Artist Name':artist,'Last Week Rank':lastweek,'Peak Rank':peak,'Weeks on board':weeks})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fd19b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5904470",
   "metadata": {},
   "source": [
    "question 7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9dbbf",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa998b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "010cecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6eceff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link naukri.com\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "38bfa4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering data Scientist jobs\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "search_job.send_keys('Data Scientist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1063f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering location\n",
    "search_loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys(\"Bangalore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4348ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click search button\n",
    "search_btn=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "495224aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#URLs of the Each jobs titles\n",
    "product_URL = []\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in url:\n",
    "        product_URL.append(i.get_attribute('href'))\n",
    "len(product_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "565b2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-data-scientist-birlasoft-noida-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-mumbai-all-areas-8-to-12-years-131222010642',\n",
       " 'https://www.naukri.com/job-listings-analystics-modeling-specialist-accenture-solutions-pvt-ltd-kolkata-mumbai-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-6-to-8-years-301122914065',\n",
       " 'https://www.naukri.com/job-listings-manager-pricewaterhouse-coopers-private-limited-mumbai-hyderabad-secunderabad-bangalore-bengaluru-7-to-9-years-201022502432',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-infosys-limited-bangalore-bengaluru-3-to-5-years-121222904491',\n",
       " 'https://www.naukri.com/job-listings-opportunity-for-biostatistician-ii-sr-principal-homebased-blg-mum-ppd-mumbai-hyderabad-secunderabad-pune-ahmedabad-chennai-bangalore-bengaluru-delhi-ncr-4-to-9-years-221019007992',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-mindtree-limited-noida-kolkata-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-5-to-10-years-081122012068',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-baker-hughes-the-network-mumbai-bangalore-bengaluru-6-to-8-years-170622500683',\n",
       " 'https://www.naukri.com/job-listings-data-analytics-lead-geo-analytics-gamma-boston-consulting-group-bangalore-bengaluru-7-to-10-years-101222500811',\n",
       " 'https://www.naukri.com/job-listings-weather-and-climate-data-scientist-shell-pvt-ltd-bangalore-bengaluru-5-to-12-years-101222500661',\n",
       " 'https://www.naukri.com/job-listings-manager-data-science-american-express-company-bangalore-bengaluru-3-to-4-years-081222501751',\n",
       " 'https://www.naukri.com/job-listings-acn-applied-intelligence-data-scientist-09-accenture-solutions-pvt-ltd-bangalore-bengaluru-2-to-6-years-071222907837',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ai-ml-engineer-hitachi-ltd-bangalore-bengaluru-3-to-7-years-081222502466',\n",
       " 'https://www.naukri.com/job-listings-python-programming-language-data-science-practitioner-accenture-solutions-pvt-ltd-bangalore-bengaluru-4-to-6-years-301122915332',\n",
       " 'https://www.naukri.com/job-listings-acn-applied-intelligence-c4di-sustainability-09-accenture-solutions-pvt-ltd-bangalore-bengaluru-4-to-6-years-301122913894',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-supply-chain-cargill-india-pvt-ltd-bangalore-bengaluru-3-to-5-years-291122915490',\n",
       " 'https://www.naukri.com/job-listings-data-science-lead-forecasting-cargill-india-pvt-ltd-bangalore-bengaluru-5-to-7-years-291122915436',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-cargill-india-pvt-ltd-bangalore-bengaluru-5-to-10-years-291122915242',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-deutsche-bank-bangalore-bengaluru-10-to-15-years-281122001753',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-caterpillar-india-private-ltd-bangalore-bengaluru-6-to-9-years-011222501078',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-lowe-s-services-india-private-limited-bangalore-bengaluru-9-to-14-years-011222008903']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b15ba94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job titles name\n",
    "name=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[1]/header/h1')\n",
    "        name.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d41b0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1cee1d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Analystics & Modeling Specialist',\n",
       " 'Manager',\n",
       " '-',\n",
       " 'Opportunity For BioStatistician - II/Sr/Principal - Homebased/Blg/Mum/',\n",
       " '-',\n",
       " 'Senior Data Scientist',\n",
       " 'Data & Analytics Lead, Geo Analytics - GAMMA',\n",
       " 'Weather and Climate Data Scientist',\n",
       " 'Manager-Data Science',\n",
       " 'ACN - Applied Intelligence - Data Scientist - 09',\n",
       " 'Data Scientist / AI-ML Engineer',\n",
       " 'Python Programming Language Data Science Practitioner',\n",
       " 'ACN - Applied Intelligence - C4DI - Sustainability - 09',\n",
       " 'Data Scientist - Supply Chain',\n",
       " 'Data Science Lead - Forecasting',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Lead Data Scientist',\n",
       " 'Lead Data Scientist']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7b65fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company names\n",
    "comp=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[1]/div/a[1]')\n",
    "        comp.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        comp.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2b20dfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ce71832d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Birlasoft',\n",
       " 'Accenture',\n",
       " 'PwC',\n",
       " '-',\n",
       " 'PPD',\n",
       " '-',\n",
       " 'Baker Hughes',\n",
       " 'Boston Consulting Group',\n",
       " 'Shell Pvt Ltd',\n",
       " 'AMERICAN EXPRESS',\n",
       " 'Accenture',\n",
       " 'Hitachi Ltd.',\n",
       " 'Accenture',\n",
       " 'Accenture',\n",
       " 'Cargill',\n",
       " 'Cargill',\n",
       " 'Cargill',\n",
       " 'Deutsche Bank',\n",
       " 'Caterpillar Inc',\n",
       " \"Lowe's\"]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8e2d9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping skill required for job\n",
    "skill=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/main/div[2]/div[2]/section[2]/div[4]/div[2]')\n",
    "        skill.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        skill.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7f314777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "59b0592d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLPAWSAnalyticsPython',\n",
       " 'BfsiConsultingMachine learningOpen sourcePython',\n",
       " 'AutomationPrototypeSimulationAnalyticalProcess improvementPackagingData miningRoboticsAnalyticsPython',\n",
       " '-',\n",
       " 'BiostatisticsStatistical Analysis',\n",
       " '-',\n",
       " 'Computer scienceData analysisSASCodingMachine learningPerlRubyAnalyticsSQLPython',\n",
       " 'Career developmentCodingAnalyticalConsultingJavascriptData processingCustomer serviceRegression analysisSQL',\n",
       " 'Cloud computingVersion controlGITMachine learningAgileInformation technologySQLPythonFortran',\n",
       " 'Product managementData modelingAnalyticalFormulationBillingMachine learningNatural language processingRisk managementFinancial servicesSQL',\n",
       " 'Computer scienceAutomationMachine learningMonitoringPython',\n",
       " 'CNeural networksBusiness analyticsProgrammingMathematicsResearchMATLABStatisticsFinancial servicesPython',\n",
       " 'ConsultingMachine learningJavascriptData processingPython',\n",
       " 'Business processData managementConsultingOracleBusiness operations',\n",
       " 'Supply Chain',\n",
       " 'Data Science',\n",
       " 'data science',\n",
       " 'Six Sigma Black BeltData AnalyticsSQL',\n",
       " 'deep learningAutomationData analysisMachine learningRegression analysisMATLABAnalyticsSix sigmaSQLPython',\n",
       " 'optimizationpricingretail']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "975acf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job description\n",
    "desc=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/main/div[2]/div[2]/section[2]/div[1]')\n",
    "        desc.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        desc.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "da66410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "effe73a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"* Analyze, design, develop, deployment and monitoring of complex AI ML solutions. Should be well versed with Python, R, Analytics, AWS QuickSight, Open source models and solutions, big data, feature engineering, Elastic search, Marklogic and cloud-infra architecture. Deep knowledge of NLP, NLU, NLG, NER, Computer Vision, Deep learning, Ontologies, Knowledge Graphs and MLOps over AWS and other clouds.\\nDomain knowledge of Life sciences, Pharma and R&D will be preferred.\\n\\n. Lead solutioning on behalf of client , develop and improve models for business solutions and improve efficiency\\n. Present solutions with story telling\\n. Strong technology decision making skills are required\\n. Define and ensure deliveries adhere to non-functional requirements and schedule.\\n. Expert in NLP and knowledge graph solution, OCR, PDF extraction, cross language model development, experience with transformers\\n. Natural Language Processing, machine translation, language detection, classification and summarization with different aspects of dealing NLP like Phonology, Morphology\\n. Experience with conversational AI and NLQ\\n. Working Knowledge along with FAIR principles, explainable AI and AI on multiple clouds\\n. Expert in accuracy and error measurement and model improvement\\n. Experience working with integration/API patterns\\n. Knowledge of Computer Vision, Deep Learning\\n. Real life project experience, following Python coding standards, design explanations and collaborating with application development teams, architects, Business and customer\\n. Ability to discover and define functional requirements, interview experts, and transform them into technical requirements and architecture definition\\n. Outstanding written and verbal communication skills and effectively influence decisions and positively\\n. Experience with Agile Methodology, Design thinking, working with ambiguity, find own path\\n. Experience with NVIDIA is desirable. Explore high-performance computing options\\n. Always ready to learn, work on self-development and team's capability development\",\n",
       " 'This role will be a part of Survey Solutions and Analytics team. The Analytics and Modeling Specialist will be working on developing advanced statistical models, machine learning methods and high-end solutions based on various datasets, helping Accenture improve various business outcome indicators.\\n\\nKEY RESPONSIBILITIES (BULLETS)\\nConceptualize, develop, test and implement various advanced Statistical models on business data.\\nIntegrate the outcomes from various analytics techniques to provide insights beyond the obvious, which helps create value for Accenture and its clients.\\nLeverage a combination of multiple approaches for project execution, including internal assets, third-party and open source solutions to create unique methods of delivery.\\nCollaborate with stakeholders, subject matter experts, client teams and other functional teams globally to understand business problems and conceptualize, design and execute solutions using various data sources and advanced analytics approach.',\n",
       " '7 - 9 years of overall experience with at least 5 years dedicated advanced analytics and ML\\nLevel of Education/ Specific Schools: Graduate/Post Graduate from reputed institute(s) with relevant experience\\nField of Experience/ Specific Degree: B.Tech./M.Tech/Masters Degree or its equivalent /MBA\\nPreferred Fields of Study : Computer and Information Science, Artificial Intelligence and Robotics, Mathematical Statistics, Statistics, Mathematics, Computer Engineering, Data Processing/Analytics/Science\\nKnowledge Required :\\nDemonstrates intimate abilities and/or a proven record of success in the following areas:\\nUnderstanding statistical or numerical methods application, data mining or data-driven problem solving\\nDemonstrating thought leader level abilities in the use of statistical modelling, algorithms, data mining and machine learning algorithms\\nDemonstrating proven delivery within a number of large scale projects\\nDemonstrating ownership of architecture solutions and managing change\\nUnderstanding business development such as client relationship management and leading and contributing to client proposals\\nCommunicating project findings orally and visually, to both technical and executive audiences\\nDeveloping people through effectively supervising, coaching, and mentoring staff\\nLeading, training, and working with other data scientists in designing effective analytical approaches taking into consideration performance and scalability to large datasets\\nManipulating and analyzing complex, high-volume, high-dimensionality data from varying sources.\\nDemonstrates intimate abilities and/or a proven record of success in the following areas:\\nDemonstrated ability to continuously learn new technologies and quickly evaluate their technical and commercial viability\\nDemonstrating thought leader-level abilities in commonly used data science packages including Spark, Pandas, SciPy, and Numpy\\nLeveraging familiarity with deep learning architectures used for text analysis, computer vision and signal processing\\nDeveloping end to end deep learning solutions for structured and unstructured data problems\\nDeveloping and deploying AI solutions as part of a larger automation pipeline\\nUtilizing programming skills and knowledge on how to write models which can be directly used in production as part of a large scale system\\nUnderstanding of not only how to develop data science analytic models but how to operationalize these models so they can run in an automated context\\nUsing common cloud computing platforms including AWS and GCP in addition to their respective utilities for managing and manipulating large data sources, model, development, and deployment\\nExperience conducting research in a lab and publishing work is a plus.\\nExperience with following technologies:\\nProgramming : Python (must) , having experience in R is a plus\\nMachine Learning Libraries : Python (Numpy, Pandas, scikit-learn, gensim, etc.), TensorFlow, Keras, PyTorch, Spark MLlib, NLTK, spaCy)\\nVisualization : Python (like Matplotlib, Seaborn, bokeh, etc.), third party libraries (like Power BI, Tableau)\\nProductionization and containerization technologies (Good to have) : GitHub, Flask, Docker, Kubernetes, Azure DevOps, GCP, Azure, AWS\\nLeadership:\\nLeading initiatives aligned with the growth of the team and of the firm\\nProviding strategic thinking, solutions and roadmaps while driving architectural recommendation\\nInteracting and collaborating with other teams to increase synergy and open new avenues of development\\nSupervising and mentoring the resources on projects\\nManaging communication and project delivery among the involved teams\\nLeading the team operations activities\\nQuickly explore new analytical technologies and evaluate their technical and commercial viability\\nWork in sprint cycles to develop proof-of-concepts and prototype models that can be demoed and explained to data scientists, internal stakeholders, and clients\\nQuickly test and reject hypotheses around data processing and machine learning model building\\nExperiment, fail quickly, and recognize when you need assistance vs. when you conclude that a technology is not suitable for the task\\nBuild machine learning pipelines that ingest, clean data, and make predictions\\nDevelop, deploy and manage production pipeline of ML models; automate the deployment pipeline\\nStay abreast of new AI research from leading labs by reading papers and experimenting with code\\nDevelop innovative solutions and perspectives on AI that can be published in academic journals/arXiv and shared with clients',\n",
       " '-',\n",
       " 'Perform management functions relating to the administrative and scientific activities\\nof specific project work and team members. Oversee statistical aspects in the design\\nand analysis of clinical trials, including project management, statistical analysis,\\nreport preparation, and advising other project statisticians. Function as Biostatistics\\nProject Leader for multiple protocols, projects, or NDA projects, including\\ncoordinating with other PPD divisions and interacting with the client and regulatory\\nagencies\\n\\nFunctions and Responsibilities:\\nBecome familiar with the activities outlined in the departments Working\\nPractice Documents and contribute changes as needed. Learn and follow\\ndepartmental procedures for statistical analyses and programming work\\nServe as a lead statistician on large and complex projects\\nLead a project team. This involves conducting team meetings, maintaining\\nproject timelines, assessing resource needs, providing resources, and budget\\npreparation. Ensure that SOPs are being followed and that appropriate\\nproject documentation is ongoing.\\nProvide sample size calculations and review protocols for completeness,\\nappropriateness of clinical design, and sound statistical analysis. Also\\ncontribute to writing appropriate protocol sections.\\nProvide randomization schemes and appropriate documentation.\\nProvide specifications for analysis database, oversee its development, and\\nassure completeness for use in all programming. Coordinate with\\nprogrammers and data management personnel as to database maintenance,\\nupdating, and documentation.\\nWrite / review analysis plans and guide others on the team in its\\nimplementation. Define appropriate methods and procedures for statistical\\nanalysis.\\nDevelop or supervise creation of table and listing specifications. Ensure that\\nproper validation for statistical tables and listings is being implemented.\\nPerform statistical analysis for key efficacy endpoints.\\nPrepare reports, manuscripts, and other documents. Contribute statistical\\nmethods section for Integrated Clinical and Statistical Report, Integrated\\nSummaries of Safety, Integrated Summaries of Efficacy, and other\\ndocuments.\\nInteract with the sponsor on all aspects of the project and present to sponsor\\nand regulatory agencies as needed.\\nUnderstand project budget as it relates to project workscope and\\ncommunicate proactively\\n\\nQualifications:\\n\\n-MS/MA degree in statistics, biostatistics, mathematics or related field and a\\nminimum of four years experience required\\n-Minimum of 5 years experience with Ph.D;. or equivalent combination of education,\\ntraining, and experience that provides the individual with the required knowledge,\\nskills and abilities.\\nPositions open for 3-14 years of experienced Bio statisticians\\nKnowledge, Skills and Abilities:\\nStrong SAS programming skills.\\nAbility to direct and promote teamwork in a multi-disciplinary team setting.\\nProven performance of required tasks, as evidenced in outstanding performance in\\ncurrent tasks and/or documented record of accomplishments.\\nEvidence of strong management skills, as shown through management of multiple\\nprojects and/or staff members.\\nDemonstrated initiative and motivation.\\nExcellent written and verbal communications skills.\\nGood organizational skills with the ability to adapt and adjust to changing priorities.\\nPositive attitude and the ability to work well with others.',\n",
       " '-',\n",
       " 'As a Senior Data Scientist, you will be responsible for:\\nContributing in development and deployment of applied, predictive and prescriptive analytics. Develop self-learning systems that can predict failures and autocorrect based on data\\nGathering analysing data, devising data science solutions for high-performance models in scalable code. Propose innovative algorithms and pursue patents where appropriate.\\nWorking with engineering teams to incorporate solutions and create intuitive UX stories. Partner with data engineers on data quality assessment, cleansing and analytics.\\nResearching and evaluating emerging technology and market trends to assist in project development and operational support for multiple teams or complex scenarios.\\nContributing to the development of software and data delivery platforms that are service-oriented with reusable components across multiple teams.\\nCreating reports and other artifacts to document your work and outcomes. Communicating methods, findings, and hypotheses with stakeholders.\\nFuel your passion\\nTo be successful in this role you will:\\nHave a MS Degree in Computer Science or in STEM, Majors. 6+ years as data scientist and technical hands-on coding experience.\\nHave experience in Machine Learning/AI techniques including Deep learning (RNN, CNN, GAN, etc), Support Vector Machines; Regularization Techniques; Boosting, Random Forests, Ensemble Methods, image/video/audio processing, Bayesian and time series modelling.\\nHave experience in Parallel programming frameworks for GPUs, TPUs and developed containerized solutions (Docker/Mesos etc).\\nHave good implementation experience with R, Python, Perl, Ruby, Scala, Apache Spark, Storm, SAS and ability to work with a variety of Deep learning frameworks including TensorFlow, Keras, Caffe, CNTK, etc\\nHave hands-on skills in sourcing, manipulating and analysing large volumes of data including SQL and NoSQL databases\\nHave proven experience in using well-established supervised and unsupervised machine learning methods for large industry-strength data analysis problems.\\nReviews, analyses and develops architectural requirements at domain level, aligning architectural requirements with software development strategy. Leads and facilitates the domains architecture governance process based on EAs governance structure.',\n",
       " 'As a Data Analytics Lead, GeoAnalytics - GAMMA, you will be a part of our GeoAnalytics capabilities. You will take formal ownership of key topics within GeoAnalytics by defining and executing strategies that includes advancing analytical capabilities, establishing core offerings, conducting business development activities, creating go-to-market content, and building an internal community around a topic. You will be solving a variety of location-based analytical problems for our clients by leading analytics teams within your technical workstream.\\n  You will be expected to establish a strong partnership with BCG case teams and clients. You will be responsible for scoping, framing, and delivering the technical workstream associated with client projects. You will utilize your knowledge of geospatial data and analytics to oversee use of a variety of tools of such as Geographic Information Systems (GIS), Python, and visualization/analytical platforms (ex. Tableau, Alteryx). You will identify and leverage a range of techniques such as geospatial clustering, network analysis, location-based optimization, and predictive analytics/modeling. Finally, you will be responsible for advising, managing, mentoring, and developing analysts through training, , and providing actionable feedback.\\n\\nYOURE GOOD AT\\n\\nProfessional capabilities\\nProblem solving, analytical skills and decision making\\nAble to effectively handle difficult and stressful situations with poise, tact and patience, while demonstrating a sense of urgency\\nAble to anticipate, identify, and solve critical problems\\nFlexible, self-motivated, and proactive out-of-the-box and critical thinke\\nCommunication, interpersonal and teaming skills\\nExcellent interpersonal and communication skills\\nFluent written and spoken English (other languages desirable)\\nAbility and willingness to give and receive honest, balanced feedback\\nWork management, organization and planning\\nExcellent organizational skills with strong attention to detail, efficient time management, and the ability to prioritize work effectively\\nIndependently and proactively communicates issues, priorities, and objectives\\nAbility to thrive in a dynamic, fast-paced, demanding environment\\nCustomer and business focus\\nStrong collaborative skills and able to adjust approach to effectively interact with customers at all organizational and technical levels\\nFocus on excellent customer service and user needs\\nValues and ethics\\nDemonstrates competence and character that inspires trust\\nAbility to respect all BCG and client information as personal and confidential\\n\\nTechnical expertise\\nDemonstrated Geospatial analytical expertise, including the ability to synthesize complex data, effectively manage complex analyses, understanding of opportunities and limitations of analytical techniques. Preferable experience in Network Modeling, Location Optimization, Site Selection Analysis, and Data Visualization.\\nExperience with statistical methods (one or more of the following): Regression Analysis, Factor Analysis, Decision Trees, Spatial Clustering\\nExperience with Web-Based GIS applications and APIs\\nVersioning software (Git, Github)\\nProgramming and/or scripting experience highly desired: e.g. Python, SQL, Javascript\\nStrong familiarity with analytical tools a plus: Alteryx, ArcGIS, CartoDB, Tableau, SQL, PostGIS, Python, R\\n\\n\\nYOU BRING (EXPERIENCE QUALIFICATIONS)\\n\\n7 to 10 years of relevant professional experience in GeoAnalytics or location-based analytics\\nRelevant degree in geospatial related field such as: Geography, Remote Sensing, Urban Planning, Statistics/GeoStatistics, Applied Mathematics, or Computer Science; advanced degree strongly preferred\\nPrevious experience working in a global organization/professional services firm is preferred\\nDemonstrated analytical project/workstream management experience (including scoping, framing, and delivery) with added focus on understanding client needs and ability to present findings effectively to stakeholders\\nExperience advising / managing / leading / guiding others on project work and in career development\\nTechnical experience/skills include GIS software (ex. ESRI ArcGIS, QGIS, CARTO), data science programming/coding in Python and/or R, and data processing/database management (ex. Alteryx, SQL)\\nWorking knowledge of descriptive statistics and statistical methods (e.g. correlation, regression, clustering, etc.) with applications in machine learning\\nExposure to BI/Data visualization platforms such as Tableau, Power BI, etc.\\nDemonstrated handling, processing, and deriving insights from remotely sensed data is a plus\\nExperience within the consulting industry is a plus\\n\\n\\nYOULL WORK WITH\\n\\nOur data analytics and artificial intelligence professionals mix deep expertise with advanced analytical methods and techniques to develop innovative solutions that help our clients tackle their most pressing issues. We design algorithms and build complex models out of large amounts of data.\\n\",',\n",
       " 'Researching machine learning models for forecasting and time series analysis using the latest methods\\nWrite clean and maintainable production-level code, including tests; the tech stack we work with includes (you don t need to have an experience with all of them): Fortran, Python (Pandas, Scikit Learn, etc.), GIT, Docker, Azure, SQL.\\nWork closely with the customer and the Product Owner day-to-day\\nWork in a highly-collaborative, friendly Agile environment, participate in Ceremonies and Continuous Improvement activities.\\nDocumenting and explaining the results of analysis or modelling to both a technical and non-technical audience.\\nLearning new engineering practices, technologies and continuously improving our Agile practices.\\nWhat we need from you\\nMinimum of MSc in Meteorological or master s degree in any relevant discipline such as Maths, Physics, Statistics and Computer Science.\\nMinimum of 5 to 12 years of overall work experience with minimum of 3 years relevant experience working with weather/climate forecast models or applying AI technologies to model predictions to improve forecast quality.\\nA good understanding of mathematical modelling of the physical processes. Optimization methods constrained by economic and operational parameters.\\nA good working knowledge of large Fortran code bases on cloud computing platforms such as Azure or AWS. Experience in recent versions of Fortran required.\\nGood understanding of model output post-processing techniques (e.g., Ensembles, Model Averaging, Model Selection) to deliver forecasts for Renewable Energy Solutions using Python or R.\\nApplication of Deep Learning Techniques for Renewable Power Forecasting applications, using Timeseries (e.g., LSTMs, GANs) and other unstructured data.\\nAbility to write clean, elegant, and maintainable production-level code in Fortran and Python. Experience in version control, testing and refactoring the code.\\nExperience with the Python scientific stack, e.g., NumPy, Pandas, Scikit-learn, PyMc3 or similar, etc.\\nExperience in weather modelling and renewable forecasting, using opensource code base such as WRF.\\n3D/4D data assimilation techniques used in physical models to improve forecast quality.\\nGood understanding of the role of weather and climate on renewable energy generation, storage and transmis',\n",
       " '  Partner with strategy teams, Ideate and contribute towards innovations to solve business problems\\nRead, Perform Literature Review and Adapt state of the art papers in AI and ML and use the concepts to come up with novel ideas for in house products\\nPerform POC on Ideas and concepts to test feasibility of solutions satisfying business objectives\\nContribute to product strategy and roadmap; recommend the nature and scope of present and future state of the AI Platforms.\\nOwn the algorithm/modelling parts of AI/ML NLP capabilities\\nTransform MVPs to production grade capabilities in collaboration with engineering teams\\nCollaborate with multiple stakeholders as Product Owner\\nContribute to patents and publication of research\\nCritical Factors to Success:\\n1.Business Outcomes:\\nDrive billing, revenue growth and profitability through advanced analytical techniques\\nMaximize business returns by institutionalizing efficient and accurate models.\\nInnovate Modeling Techniques for accurate, faster and scalable models\\nUse of advanced techniques in Machine Learning/NLP/Document intelligence to solve complex business problems\\n2. Leadership Outcomes:\\nPut enterprise thinking first, connect the role’s agenda to enterprise priorities and balance the needs of customers, partners, colleagues shareholders.\\nLead with an external perspective, challenge status quo and bring continuous innovation to our existing offerings\\nDemonstrate learning agility, make decisions quickly and with the highest level of integrity\\nLead with a digital mindset and deliver the world’s best customer experiences every day\\nMinimum Qualifications:\\n3-4 years of experience post bachelors/master or 18 months of experience post PhD from reputed institutions with a degree in a quantitative field like Computer Science, Statistics or Engineering.\\n\\nFunctional Skills/Capabilities:\\nAbility to drive project deliverables to achieve business results\\nAbility to work effectively in a team environment\\nStrong communication and interpersonal skills\\nAbility to learn quickly and work independently with complex, unstructured initiatives\\nAbility to Integrate With Cross-Functional Business Partners Worldwide\\nGood Programming skills are a must\\nExcellent problem formulation and solving skills\\n\\nTechnical Skills/Capabilities:\\nHands on with Python, SQL, Python ML and DL libraries\\nSound Theoretical understanding of Advanced Statistical and Machine Learning techniques\\nFamiliarity with Predictive models XGBoost, RNN, LSTM\\nStrong background in Unstructured data analytics and Natural Language Processing\\nFamiliarity with Wor2Vec / Clustering / Gensim / Spacy / NLTK / GloVe and pre trained models like BERT\\nHands on programming and ability to design robust pre-processing and Tabular/Unstructured Data modeling pipelines\\nKnowledge of Platforms:\\nAny Big Data Framework- Hadoop, Hive, Pyspark\\nExposure to cloud platforms i.e. AWS\\nBehavioral Skills/Capabilities:\\n\\nEnterprise Leadership Behaviors\\nSet The Agenda: Define What Winning Looks Like, Put Enterprise Thinking First, Lead with an External Perspective\\nBring Others with You: Build the Best Team, Seek Provide Coaching Feedback, Make Collaboration Essential\\nDo It the Right Way: Communicate Frequently, Candidly Clearly, Make Decisions Quickly Effectively, Live the Blue Box Values, Great Leadership Demands Courage',\n",
       " 'The Data Science Analytics Specialist will work closely with client-side technical stakeholders and support day to day delivery of the solution to client. The role will play a key role in monitoring team’s progress towards developing new innovative and impactful solutions and delivering them. It will support data assurance and reporting processes and provide valuable insights through analysis. Finally, the team member will work within the larger Insurance practice as well as cross-functionally with other teams within Accenture’s Applied Intelligence practice to bring best-in-class assets to bear in solving some of the most challenging problems in Insurance.\\nKey Qualifications\\n•Strong knowledge of common language model architectures and comfortable with tinkering with them to fit business-specific use cases\\n•Strong foundation in core statistics/ machine learning concepts\\n•Solid knowledge of and experience in Python, including related data science libraries and deep learning frameworks\\n•Curiosity and attention to detail\\n•Strong communicator with visual, verbal, and writing skills to clearly articulate complex design problems and solutions\\n•Adaptable to changing technology and restrictions, design challenges, deadlines, and project requirements\\n•Strong team player with ability to collaborate seamlessly with several teams spread across the globe',\n",
       " '1. Research and Develop Innovative Solutions and Quantitative Models for positive impact on Hitachi s business (e.g., Energy, Industry, Mobility, Smart Life and Financial Services).\\n2. Provide RD support to Hitachi business units and group companies for commercialization of research prototypes. This includes Design, Implementation and Demonstration of Proof-of-Concept (PoC) and Working Proto-types,. Exploration of emerging tools, techniques, and technologies are expected.\\n3. Collaborate with cross-functional teams, eco-system partners and academia for business benefit.\\n4. Generate eminence via patents, publications, thought leadership, invited speakerships and conspicuous presence in forums of repute.\\n5. Add value to self through continuous learning and knowledge acquisition.\\nRequirements:\\n1. Academic Qualification: Bachelor s degree in any discipline with strong quantitative flavor (e.g., STEM background like that in Science, Technology, Engineering and Management). Advanced qualifications like candidates with Master s or Doctorate are welcome.\\n2. Strong Fundamentals: The candidate is required to build scientific models from first principles and hence need to have excellent understanding of basics in mathematics and statistics (e.g., differential equations, linear algebra, matrix, combinatorics, probability, Bayesian statistics, eigen vectors, Markov models, Fourier analysis). Understanding of basic principles of business analytics like statistical distributions, regression, segmentation, decision-science algorithms is mandatory. Understanding of working principles of neural networks and underlying algorithms (e.g., CNN, RNN, LSTM, back-propagation, loss-functions, gradient descent) is a plus .\\n3. Hands-on Programming: Good programming skills in any one of the following languages is mandatory: C / C / Java / Python / Matlab.\\n4. Communication : Ability to articulate key messages concisely and precisely.\\n5. Collaboration: Good inter-personal and teaming skills.',\n",
       " 'Key Responsibilities : DM-369- Understanding of machine learning algorithms2 Experience in working with graph databases and document DBs3 Hands on experience in writing complex SQL queries4 Hands on experience in building machine learning solutions in Python6 Basic understanding of statistical distributions and probability theory7 Proficiency in general python programming8 Experience in data visualization using opensource libraries in python, javascript and dashboarding tools like superset or powerBI\\nTechnical Experience : Experience in DevOps practices for machine learning Experience with building KPIs for customer, product and market insights Experience in Spark based data processing and machine learning Experience in building and deploying solutions on AWS Hands on experience with sagemaker pipelines Hands on experience with airflow\\nProfessional Attributes : oDefines success in terms of the entire team oAction oriented and has exceptional attitude and work ethic oStrong Desire to learn and improve technical and interpersonal skills',\n",
       " 'We are looking for a highly motivated and passionate Data Science Consultant to join Accenture’s Global Centre for Data and Insights. The vision of the Centre is to combine the power of Machine (data & AI) with Human (Knowledge Experts) to solve some of the most complex problems in the industry. As a key member of the team, your role will focus on providing world class insights to leaders and stakeholders across different Functions in Banking.\\nWhat you will focus on?\\n? Conduct analysis to address critical business challenges faced by client teams working in different markets across the banking value chain to recommend the best data and insights powered solutions\\n? Gathering business requirements to create high level business solution framework covering aspects of banking customer journey, policy & regulatory requirements, data driven business process design & Technology Architecture\\n? Interface with client teams along with inputs from internal research and data insights teams to develop solutions for identified opportunities across banking LOBs\\n? Build analytical use cases in AI and Machine Learning across different banking functions including Operations, Treasury and Finance, Risk assessment, Compliance and Regulatory, Fraud, IT and Technology, Product design and Marketing, AI driven Customer Experience\\n? Ability to work with large data sets and present findings / insights to key stakeholders; Data management using databases like SQL, Oracle, S3 buckets and likes of the same\\n? Use data driven processes; generate actionable insights and recommend client strategy by interpreting ML model outputs, propensity scores to help prioritize recommendations for clients\\n? Build client deliverables with experience in storyboarding and client problem solving\\n? Enhance the business solutions with inputs from internal research and data insights teams for identified opportunities across banking LOBs',\n",
       " \"The Supply Chain Data Scientist will work collaboratively in multidisciplinary teams to define, develop, deploy and sustain complex supply chain digital solutions at scale. In this role, you will deploy predictive and optimization models for digital supply chain products that help deliver significant value to our customers, businesses and functions.\\n\\n\\nKey Accountabilities\\n• Design, implement, and deploy forecasting solutions on C3.ai the platform.\\n• Continuously seek out best practices and develop skills.\\n• Work on multidisciplinary teams of data engineers, software engineers, data scientists, and business subject matter experts to deliver projects on time and within budgets.\\n• Translate ambiguous business problems into project charters clearly identifying technical risks and project scope.\\n• Take ownership for the entire data science workflow including well defined project scoping, exploratory data analysis, model development, deployment and monitoring.\\n• Independently solve moderately complex issues with minimal supervision, while escalating more complex issues to appropriate staff.\\n• Other duties as assigned\\n\\n\\nQualifications\\nMINIMUM QUALIFICATIONS\\n• Bachelor’s degree in data science, computer science, math, engineering or related field or equivalent experience,\\n• Confirmed ability to present to non technical audiences\\n• Strong mathematical background (linear algebra, calculus, probability and statistics).\\n• Experience with JavaScript and prototyping languages such as Python and R.\\n• Applied Machine Learning experience (regression analysis, time series, probabilistic models, supervised, classification and unsupervised learning).\\n• Minimum of two years of related work experience, Other minimum qualifications may apply\\nPREFERRED QUALIFICATIONS\\n• Master's degree or PhD in data science, computer science, math, engineering or related field\\n• Strong data visualization skills\\n• Strong SQL skills\\n• Experience working with continuous integration and delivery (CI/CD) pipelines\\n• Professional experience applying predictive models for Supply Chain solutions.\\n• Experience with timeseries forecasting (such as ARIMA, Prophet, DeepAR, etc.)\\n• Experience in software development environment and code management or versioning\",\n",
       " \"Job Purpose and Impact\\nIntelligent Supply Chain Forecasting Lead will work collaboratively in multidisciplinary teams to define, develop, deploy and sustain complex supply chain digital solutions at scale. In this role, you will deploy predictive, prescriptive models at scale for digital supply chain products that help deliver significant value to our customers, businesses and functions.\\n\\n\\nKey Accountabilities\\nOwn and design statistical model, evaluate differentiating features and deploy forecasting solutions keeping eye on bringing business value for intelligent supply chain applications.\\nWork on multidisciplinary teams of product owners, data engineers, software engineers, data scientists, and business subject-matter experts to deploy complex large-scale projects on time.\\nTake ownership for the entire supply chain data science workflow including well defined, highly complex project scoping, exploratory data analysis, model development, deployment and monitoring.\\nProvide expert thought leadership in your space and work with limited direction, using additional research and interpretation to identify issues or problems. You may provide direction to supporting team members and be a strategic contributor.\\nContinuously seek out best practices and develop skills.\\nOther duties as assigned.\\n\\n\\nQualifications\\nMINIMUM QUALIFICATIONS\\n• Bachelor’s degree in Computer science, Statistics, Math OR related field OR Equivalent Experience.\\n• Applied Machine Learning experience (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning).\\n• Strong mathematical background (linear algebra, calculus, probability and statistics). • Experience with JavaScript and prototyping languages such as Python and R.\\n• Minimum of Six years of related work experience.\\nPREFERRED QUALIFICATIONS\\n• Master's degree or PhD in Computer science / Engineering / Math or Statistics\\n• Professional experience applying predictive, prescriptive models for Supply Chain solutions.\\n• Experience with timeseries forecasting such as ARIMA, Prophet, DeepAR, etc.\",\n",
       " 'Job Purpose and Impact\\nIntelligent Supply Chain Senior Data Scientist will work collaboratively in multidisciplinary teams to define, develop and deploy complex supply chain digital solutions at scale. In this role, you will deploy predictive, prescriptive and optimization models at scale for digital supply chain products that help deliver significant value to our customers, businesses and functions.\\n\\n\\nKey Accountabilities\\nDesign, implement, and deploy forecasting, predictive solutions\\nContinuously seek out best practices and develop skills.\\nContribute to design, and implementation of new features, and deploy predictive models and solutions for intelligent supply chain products at scale.\\nWork and consult on multidisciplinary teams of data engineers, software engineers, data scientists, and business subject-matter experts to deliver highly complex large-scale projects on time.\\nTake ownership and work with limited supervision for the entire supply chain data science workflow including well defined, highly complex project scoping, exploratory data analysis, model development, deployment and monitoring.\\nProvide expert thought leadership in the area of business analytics and work with limited direction, using additional research and interpretation to identify issues or problems.\\nYou may provide direction to supporting team members and other duties as assigned\\n\\n\\nMINIMUM QUALIFICATIONS\\n• Master’s degree in Management, Computer science, Statistics, Data Science OR related field OR Equivalent Experience.\\n• Applied Machine Learning experience (regression analysis, time series, probabilistic models, supervised classification and unsupervised learning).\\n• Strong mathematical background (linear algebra, calculus, probability and statistics).\\n• Strong coding skills in Python (or similar object-oriented programming language).\\n• Minimum of 4 years of related work experience.\\nPREFERRED QUALIFICATIONS\\n• Five or more years’ experience in Supply chain\\n• PhD in Computer science, Artificial Intelligence, Optimization, Operational Research, or Math OR related field.\\n• Professional experience applying predictive models for Supply Chain solutions.\\n• Experience with timeseries forecasting such as ARIMA, Prophet, DeepAR, etc.',\n",
       " 'Job Title: Data Scientist / Data Analyst - AVP\\nLocation: Bangalore\\n\\nRole Description\\n\\nThe Data Scientist / Data Analyst has a proven track record of gaining insights from analysing company data, adept at using large data sets to find opportunities for process improvement and process optimisation and using models to test the effectiveness of different courses of action. With strong experience in using a variety of data mining/data analysis methods, using a variety of data tools, building, and implementing models, using/creating algorithms and creating/running simulations. With proven ability in driving business results with their data-based insights, comfortable working with a wide range of stakeholders and functional teams. With a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\\n\\nWhat well offer you\\n\\nAs part of our flexible scheme, here are just some of the benefits that youll enjoy\\nBest in class leave policy\\nGender neutral parental leaves\\n100% reimbursement under child care assistance benefit (gender neutral)\\nFlexible working arrangements\\nSponsorship for Industry relevant certifications and education\\nEmployee Assistance Program for you and your family members\\nComprehensive Hospitalization Insurance for you and your dependents\\nAccident and Term life Insurance\\nComplementary Health screening for 35 yrs. and above\\n\\nYour skills and experience\\n\\nStrong problem-solving skills with an emphasis on process analysis and improvement\\nExperience using statistical computer languages SQL (expert level), Python etc. to manipulate data and draw insights from large data sets.\\nLean Six Sigma black belt, experienced in working in a regulated transactional environment\\nCelonis analytical skills for process mining is desirable\\nExperience working with and creating data architectures.\\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experienced with applications of these techniques.\\nExcellent written and verbal communication skills for coordinating across teams.\\nA drive to learn and master new technologies and techniques.\\nExperienced in using SQL to assist in Data analysis\\nOverall work experience of 10-15 years',\n",
       " 'Work closely with business stakeholders to understand their goals determine how Data analytics can be used to achieve those goals.\\nShould be able to design data modelling processes, create algorithms develop predictive models to help analyze the data\\nDevelop prediction tools which can help Caterpillar customers to gain efficiency and plan the forecast better\\nDevelop innovative solutions which enables machine learning and prediction. Also , Work with Cross - functional team to come up with innovative solutions\\nAct as a Technical lead in the field of Analytics and Machine Learning.\\nRequired skills :\\nStrong knowledge in python, SQL\\nFully skilled in Visualization tools such as Power Bi , Tableau with ability to utilize it as Automation tool\\nShould be able to develop Data Analysis Algorithm\\nShould have experience in developing prediction formulas for non-linear data.\\nSelf - starter passionate for Data analysis\\nCan make use of statistical tools for data prediction. Regression analysis (Linear/Non-linear)\\nShould be able to present the data in a meaningful form\\nPassion for Innovation and Technology\\nSelf-Starter, Should be able to present Ideas to stakeholders\\nDesired Skill\\nGood understanding of Six Sigma tools\\nCan develop Matlab models on the deep learning toolbox\\nShould be able to translate Data requirement into analytics\\nPositive outlook, strong work ethic, willingness to learn and grow\\nExcellent communication skills',\n",
       " 'Roles and Responsibilities\\nThe primary purpose of this role is to provide advanced analytical capabilities to support data science initiatives. This position gains experience in various areas including, but not limited to: predictive modeling; personalization and recommendation algorithms; natural language processing and text mining; search recall, precision, ranking, and related problems; optimization and mathematical programming with applications in labor scheduling, inventory and capacity planning, network flows, and supply chain optimization.\\n\\nA Lead Data Scientist solves highly complex problems that do not yet have solutions in the research and span much of the Data Science portfolio. Therefore, the individual in this role must be an expert in his/her field and confident in interacting and proposing solutions to the business. This role influences the thought process and methodology for other team members.\\n\\nQualifications:\\nMinimum Qualifications\\n10+ years of experience in data science or advanced analytics in industry\\nData Science experience in Retail is mandatory\\nData Science experience in Pricing function in Retail will be a plus\\n5+ years of experience in data science or advanced analytics in industry\\nKnowledge of SQL and various statistical modeling or machine learning techniques\\nMandatory experience in Python, Pyspark, Spark.\\nProgramming experience (Python, Java, Scala, Rust, etc.)\\nExperience using multiple data systems and sources (such as Hadoop, Spark, Aster, Teradata, etc.)']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0df47917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job locations\n",
    "loc=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[3]/span')\n",
    "        loc.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        loc.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cedf7b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "95f3dda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " '-',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " '-',\n",
       " 'Mumbai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "409574bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Birlasoft</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NLPAWSAnalyticsPython</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Chennai, ...</td>\n",
       "      <td>* Analyze, design, develop, deployment and mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>BfsiConsultingMachine learningOpen sourcePython</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>This role will be a part of Survey Solutions a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PwC</td>\n",
       "      <td>Manager</td>\n",
       "      <td>AutomationPrototypeSimulationAnalyticalProcess...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>7 - 9 years of overall experience with at leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPD</td>\n",
       "      <td>Opportunity For BioStatistician - II/Sr/Princi...</td>\n",
       "      <td>BiostatisticsStatistical Analysis</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Perform management functions relating to the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baker Hughes</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Computer scienceData analysisSASCodingMachine ...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>As a Senior Data Scientist, you will be respon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>Data &amp; Analytics Lead, Geo Analytics - GAMMA</td>\n",
       "      <td>Career developmentCodingAnalyticalConsultingJa...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>As a Data Analytics Lead, GeoAnalytics - GAMMA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shell Pvt Ltd</td>\n",
       "      <td>Weather and Climate Data Scientist</td>\n",
       "      <td>Cloud computingVersion controlGITMachine learn...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Researching machine learning models for foreca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>Product managementData modelingAnalyticalFormu...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Partner with strategy teams, Ideate and cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Data Scientist - 09</td>\n",
       "      <td>Computer scienceAutomationMachine learningMoni...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The Data Science Analytics Specialist will wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>Data Scientist / AI-ML Engineer</td>\n",
       "      <td>CNeural networksBusiness analyticsProgrammingM...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>1. Research and Develop Innovative Solutions a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>Python Programming Language Data Science Pract...</td>\n",
       "      <td>ConsultingMachine learningJavascriptData proce...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Key Responsibilities : DM-369- Understanding o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - C4DI - Sustainabi...</td>\n",
       "      <td>Business processData managementConsultingOracl...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>We are looking for a highly motivated and pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cargill</td>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Supply Chain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>The Supply Chain Data Scientist will work coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cargill</td>\n",
       "      <td>Data Science Lead - Forecasting</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job Purpose and Impact\\nIntelligent Supply Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cargill</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>data science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job Purpose and Impact\\nIntelligent Supply Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Six Sigma Black BeltData AnalyticsSQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job Title: Data Scientist / Data Analyst - AVP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Caterpillar Inc</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>deep learningAutomationData analysisMachine le...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Work closely with business stakeholders to und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lowe's</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>optimizationpricingretail</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nThe primary purpos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company  \\\n",
       "0                 Birlasoft   \n",
       "1                 Accenture   \n",
       "2                       PwC   \n",
       "3                         -   \n",
       "4                       PPD   \n",
       "5                         -   \n",
       "6              Baker Hughes   \n",
       "7   Boston Consulting Group   \n",
       "8             Shell Pvt Ltd   \n",
       "9          AMERICAN EXPRESS   \n",
       "10                Accenture   \n",
       "11             Hitachi Ltd.   \n",
       "12                Accenture   \n",
       "13                Accenture   \n",
       "14                  Cargill   \n",
       "15                  Cargill   \n",
       "16                  Cargill   \n",
       "17            Deutsche Bank   \n",
       "18          Caterpillar Inc   \n",
       "19                   Lowe's   \n",
       "\n",
       "                                          Designation  \\\n",
       "0                                      Data Scientist   \n",
       "1                    Analystics & Modeling Specialist   \n",
       "2                                             Manager   \n",
       "3                                                   -   \n",
       "4   Opportunity For BioStatistician - II/Sr/Princi...   \n",
       "5                                                   -   \n",
       "6                               Senior Data Scientist   \n",
       "7        Data & Analytics Lead, Geo Analytics - GAMMA   \n",
       "8                  Weather and Climate Data Scientist   \n",
       "9                                Manager-Data Science   \n",
       "10   ACN - Applied Intelligence - Data Scientist - 09   \n",
       "11                    Data Scientist / AI-ML Engineer   \n",
       "12  Python Programming Language Data Science Pract...   \n",
       "13  ACN - Applied Intelligence - C4DI - Sustainabi...   \n",
       "14                      Data Scientist - Supply Chain   \n",
       "15                    Data Science Lead - Forecasting   \n",
       "16                              Senior Data Scientist   \n",
       "17                                     Data Scientist   \n",
       "18                                Lead Data Scientist   \n",
       "19                                Lead Data Scientist   \n",
       "\n",
       "                                               Skills  \\\n",
       "0                               NLPAWSAnalyticsPython   \n",
       "1     BfsiConsultingMachine learningOpen sourcePython   \n",
       "2   AutomationPrototypeSimulationAnalyticalProcess...   \n",
       "3                                                   -   \n",
       "4                   BiostatisticsStatistical Analysis   \n",
       "5                                                   -   \n",
       "6   Computer scienceData analysisSASCodingMachine ...   \n",
       "7   Career developmentCodingAnalyticalConsultingJa...   \n",
       "8   Cloud computingVersion controlGITMachine learn...   \n",
       "9   Product managementData modelingAnalyticalFormu...   \n",
       "10  Computer scienceAutomationMachine learningMoni...   \n",
       "11  CNeural networksBusiness analyticsProgrammingM...   \n",
       "12  ConsultingMachine learningJavascriptData proce...   \n",
       "13  Business processData managementConsultingOracl...   \n",
       "14                                       Supply Chain   \n",
       "15                                       Data Science   \n",
       "16                                       data science   \n",
       "17              Six Sigma Black BeltData AnalyticsSQL   \n",
       "18  deep learningAutomationData analysisMachine le...   \n",
       "19                          optimizationpricingretail   \n",
       "\n",
       "                                             Location  \\\n",
       "0   Noida, Hyderabad/Secunderabad, Pune, Chennai, ...   \n",
       "1   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "2   Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "3                                                   -   \n",
       "4   Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...   \n",
       "5                                                   -   \n",
       "6                         Mumbai, Bangalore/Bengaluru   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8                                 Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11                                Bangalore/Bengaluru   \n",
       "12                                Bangalore/Bengaluru   \n",
       "13                                Bangalore/Bengaluru   \n",
       "14                                Bangalore/Bengaluru   \n",
       "15                                Bangalore/Bengaluru   \n",
       "16                                Bangalore/Bengaluru   \n",
       "17                                Bangalore/Bengaluru   \n",
       "18                                Bangalore/Bengaluru   \n",
       "19                                Bangalore/Bengaluru   \n",
       "\n",
       "                                          Description  \n",
       "0   * Analyze, design, develop, deployment and mon...  \n",
       "1   This role will be a part of Survey Solutions a...  \n",
       "2   7 - 9 years of overall experience with at leas...  \n",
       "3                                                   -  \n",
       "4   Perform management functions relating to the a...  \n",
       "5                                                   -  \n",
       "6   As a Senior Data Scientist, you will be respon...  \n",
       "7   As a Data Analytics Lead, GeoAnalytics - GAMMA...  \n",
       "8   Researching machine learning models for foreca...  \n",
       "9     Partner with strategy teams, Ideate and cont...  \n",
       "10  The Data Science Analytics Specialist will wor...  \n",
       "11  1. Research and Develop Innovative Solutions a...  \n",
       "12  Key Responsibilities : DM-369- Understanding o...  \n",
       "13  We are looking for a highly motivated and pass...  \n",
       "14  The Supply Chain Data Scientist will work coll...  \n",
       "15  Job Purpose and Impact\\nIntelligent Supply Cha...  \n",
       "16  Job Purpose and Impact\\nIntelligent Supply Cha...  \n",
       "17  Job Title: Data Scientist / Data Analyst - AVP...  \n",
       "18  Work closely with business stakeholders to und...  \n",
       "19  Roles and Responsibilities\\nThe primary purpos...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Company':comp,'Designation':name,'Skills':skill,'Location':loc,'Description':desc})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e4ed6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c25e79",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee042c51",
   "metadata": {},
   "source": [
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "19b038b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import nec library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d0f49495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82d025d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4e38e30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Rank\n",
    "rank=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[1]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    rank.append(name.text)\n",
    "rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "005eb3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping  Book Name\n",
    "book=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[2]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    book.append(name.text)\n",
    "book\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "55fa2f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Author Name\n",
    "Author=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[3]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    Author.append(name.text)\n",
    "Author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "634f56a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Volume sold\n",
    "volume=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[4]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    volume.append(name.text)\n",
    "volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5dc30356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Publisher\n",
    "publisher=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[5]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    publisher.append(name.text)\n",
    "publisher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "435c1eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrapping Genre\n",
    "genre=[]\n",
    "names = driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tbody/tr/td[6]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    genre.append(name.text)\n",
    "genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f4a2c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Book Name       Author Name  \\\n",
       "0     1                                  Da Vinci Code,The        Brown, Dan   \n",
       "1     2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2     3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3     4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4     5                               Fifty Shades of Grey      James, E. L.   \n",
       "..  ...                                                ...               ...   \n",
       "95   96                                          Ghost,The    Harris, Robert   \n",
       "96   97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97   98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98   99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Rank':rank,'Book Name':book,'Author Name':Author,'Volume Sold':volume,'Publisher':publisher,'Genre':genre})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "10851cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"table-cell-10943--1-1\"]/div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ce1ac",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7d7e82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1c662d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc10c9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series Names\n",
    "ser=[]\n",
    "names = driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    ser.append(name.text)\n",
    "ser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "790803a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011–2019)',\n",
       " '(2016– )',\n",
       " '(2010–2022)',\n",
       " '(2017–2020)',\n",
       " '(2014–2020)',\n",
       " '(2013–2019)',\n",
       " '(2017– )',\n",
       " '(2005– )',\n",
       " '(2014–2023)',\n",
       " '(2012–2020)',\n",
       " '(2017–2021)',\n",
       " '(2007–2019)',\n",
       " '(2011–2019)',\n",
       " '(2010–2017)',\n",
       " '(2013–2020)',\n",
       " '(2010–2017)',\n",
       " '(2009–2017)',\n",
       " '(2011– )',\n",
       " '(2008–2013)',\n",
       " '(2016–2021)',\n",
       " '(2005–2020)',\n",
       " '(2005–2017)',\n",
       " '(2014–2020)',\n",
       " '(2011–2017)',\n",
       " '(1989– )',\n",
       " '(2011–2018)',\n",
       " '(2015–2017)',\n",
       " '(2015–2018)',\n",
       " '(1994–2004)',\n",
       " '(2005–2014)',\n",
       " '(2011–2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2018)',\n",
       " '(2015– )',\n",
       " '(2007–2012)',\n",
       " '(2015–2018)',\n",
       " '(2014–2019)',\n",
       " '(2016–2022)',\n",
       " '(2015–2019)',\n",
       " '(2009–2020)',\n",
       " '(2013– )',\n",
       " '(2016–2019)',\n",
       " '(2017–2019)',\n",
       " '(2013–2018)',\n",
       " '(2017–2020)',\n",
       " '(2018– )',\n",
       " '(2019– )',\n",
       " '(2011–2021)',\n",
       " '(2011–2018)',\n",
       " '(2013–2020)',\n",
       " '(2018– )',\n",
       " '(2006–2013)',\n",
       " '(2015– )',\n",
       " '(1999– )',\n",
       " '(2013– )',\n",
       " '(2004–2010)',\n",
       " '(2013–2022)',\n",
       " '(2004–2012)',\n",
       " '(2015–2018)',\n",
       " '(2013–2017)',\n",
       " '(2011–2020)',\n",
       " '(2015–2020)',\n",
       " '(2016–2022)',\n",
       " '(2017– )',\n",
       " '(2018–2020)',\n",
       " '(2017– )',\n",
       " '(2014–2019)',\n",
       " '(2009–2015)',\n",
       " '(1997– )',\n",
       " '(2013–2021)',\n",
       " '(2013–2015)',\n",
       " '(2019–2023)',\n",
       " '(2014–2019)',\n",
       " '(2016–2019)',\n",
       " '(2004–2012)',\n",
       " '(2015–2022)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2017–2021)',\n",
       " '(2017–2022)',\n",
       " '(2016–2022)',\n",
       " '(2016–2020)',\n",
       " '(2017–2018)',\n",
       " '(2018–2020)',\n",
       " '(2017–2019)',\n",
       " '(2011–2015)',\n",
       " '(2016–2018)',\n",
       " '(2012–2018)',\n",
       " '(2017)',\n",
       " '(2017–2019)',\n",
       " '(2018–2019)',\n",
       " '(2008–2015)',\n",
       " '(2016– )',\n",
       " '(2019)',\n",
       " '(2015–2019)',\n",
       " '(2013–2017)',\n",
       " '(2017–2019)',\n",
       " '(2005– )',\n",
       " '(2015–2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series Years\n",
    "year=[]\n",
    "names = driver.find_elements(By.XPATH,'//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    year.append(name.text)\n",
    "year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fdceb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series genre\n",
    "gen=[]\n",
    "names = driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    gen.append(name.text)\n",
    "gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "eff94694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series runtime\n",
    "watchtime=[]\n",
    "names = driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    watchtime.append(name.text)\n",
    "watchtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7d26a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 2,093,285',\n",
       " ' 1,182,787',\n",
       " ' 990,687',\n",
       " ' 293,252',\n",
       " ' 252,443',\n",
       " ' 303,264',\n",
       " ' 145,670',\n",
       " ' 309,481',\n",
       " ' 346,612',\n",
       " ' 432,232',\n",
       " ' 476,857',\n",
       " ' 808,201',\n",
       " ' 546,706',\n",
       " ' 925,428',\n",
       " ' 532,437',\n",
       " ' 168,205',\n",
       " ' 322,703',\n",
       " ' 320,151',\n",
       " ' 1,876,863',\n",
       " ' 324,987',\n",
       " ' 446,293',\n",
       " ' 535,973',\n",
       " ' 152,474',\n",
       " ' 149,182',\n",
       " ' 407,864',\n",
       " ' 225,645',\n",
       " ' 422,583',\n",
       " ' 441,262',\n",
       " ' 994,269',\n",
       " ' 683,931',\n",
       " ' 411,404',\n",
       " ' 388,159',\n",
       " ' 136,800',\n",
       " ' 124,508',\n",
       " ' 175,665',\n",
       " ' 155,144',\n",
       " ' 231,116',\n",
       " ' 505,577',\n",
       " ' 215,385',\n",
       " ' 431,301',\n",
       " ' 521,414',\n",
       " ' 64,213',\n",
       " ' 191,400',\n",
       " ' 505,033',\n",
       " ' 387,107',\n",
       " ' 79,974',\n",
       " ' 281,362',\n",
       " ' 243,759',\n",
       " ' 225,393',\n",
       " ' 217,792',\n",
       " ' 241,409',\n",
       " ' 725,915',\n",
       " ' 130,625',\n",
       " ' 340,507',\n",
       " ' 250,132',\n",
       " ' 554,054',\n",
       " ' 547,908',\n",
       " ' 465,493',\n",
       " ' 61,296',\n",
       " ' 111,616',\n",
       " ' 342,333',\n",
       " ' 74,466',\n",
       " ' 105,327',\n",
       " ' 237,888',\n",
       " ' 96,026',\n",
       " ' 95,817',\n",
       " ' 51,273',\n",
       " ' 149,094',\n",
       " ' 369,958',\n",
       " ' 316,843',\n",
       " ' 107,105',\n",
       " ' 248,705',\n",
       " ' 571,263',\n",
       " ' 105,594',\n",
       " ' 129,750',\n",
       " ' 527,283',\n",
       " ' 108,857',\n",
       " ' 236,935',\n",
       " ' 89,687',\n",
       " ' 22,918',\n",
       " ' 144,650',\n",
       " ' 161,132',\n",
       " ' 131,883',\n",
       " ' 37,671',\n",
       " ' 289,347',\n",
       " ' 120,557',\n",
       " ' 131,969',\n",
       " ' 74,404',\n",
       " ' 108,630',\n",
       " ' 200,017',\n",
       " ' 29,186',\n",
       " ' 185,923',\n",
       " ' 218,138',\n",
       " ' 750,226',\n",
       " ' 68,792',\n",
       " ' 50,246',\n",
       " ' 61,613',\n",
       " ' 198,847',\n",
       " ' 41,618',\n",
       " ' 245,763']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series Upvote\n",
    "vote=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"lister-item mode-detail\"]/div/p[4]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    vote.append(name.text.split(':')[1])\n",
    "vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2cc3764f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '8.9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.4',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping Series Ratings\n",
    "rating=[]\n",
    "names = driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div/div/span[2]')\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    rating.append(name.text)\n",
    "    \n",
    "rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2b4e83dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,093,285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,182,787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>990,687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>293,252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings       Votes  \n",
       "0    57 min     9.2   2,093,285  \n",
       "1    51 min     8.7   1,182,787  \n",
       "2    44 min     8.1     990,687  \n",
       "3    60 min     7.5     293,252  \n",
       "4    43 min     7.6     252,443  \n",
       "..      ...     ...         ...  \n",
       "95   42 min     7.4      50,246  \n",
       "96   50 min     7.8      61,613  \n",
       "97   42 min     8.1     198,847  \n",
       "98   45 min     7.1      41,618  \n",
       "99  572 min     8.6     245,763  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Name':ser,'Year Span':year,'Genre':gen,'Run Time':watchtime,'Ratings':rating,'Votes':vote})\n",
    "DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c1cde46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f90f65",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "\n",
    "    You have to find the following details:\n",
    "\n",
    "        A) Dataset name\n",
    "\n",
    "        B) Data type\n",
    "\n",
    "        C) Task\n",
    "\n",
    "        D) Attribute type\n",
    "\n",
    "        E) No of instances\n",
    "\n",
    "        F) No of attribute\n",
    "\n",
    "        G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "40fe102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import nec library\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import re\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9e8fdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\91939\\Downloads\\selnium\\chromedriver.exe')\n",
    "\n",
    "\n",
    "#maximize the automated window\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "00a0963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the link\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "49acb10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#URLs of the Datasets\n",
    "product_URL = []\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//td[@valign=\"middle\"]//table//tbody//tr/td//span//a')\n",
    "    for i in url:\n",
    "        product_URL.append(i.get_attribute('href'))\n",
    "len(product_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "927b732d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://archive.ics.uci.edu/ml/datasets/Average+Localization+Error+%28ALE%29+in+sensor+node+localization+process+in+WSNs',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/9mers+from+cullpdb',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/TamilSentiMix',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Accelerometer',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Synchronous+Machine+Data+Set',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Synchronous+Machine+Data+Set',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Pedal+Me+Bicycle+Deliveries',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wikipedia+Math+Essentials',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Turkish+Headlines+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Secondary+Mushroom+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Power+consumption+of+Tetouan+city',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Iris',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Adult',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wine',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Heart+Disease',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Wine+Quality',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Rice+%28Cammeo+and+Osmancik%29',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Bank+Marketing',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Car+Evaluation',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Raisin+Dataset',\n",
       " 'https://archive.ics.uci.edu/ml/datasets/Abalone']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3956d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Dataset Names\n",
    "dataname=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[1]/tbody/tr/td[1]/p[1]/span[1]/b')\n",
    "        dataname.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        dataname.append('-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0b46b",
   "metadata": {},
   "source": [
    "dataname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8799ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Dataset datatypes\n",
    "datatype=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p')\n",
    "        datatype.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        datatype.append('-')\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "bff15d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multivariate',\n",
       " 'Sequential',\n",
       " 'N/A',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Time-Series',\n",
       " 'Time-Series',\n",
       " 'Time-Series',\n",
       " 'Text',\n",
       " 'Univariate',\n",
       " 'Multivariate, Time-Series',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Data Types',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "42e25885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrapping Dataset task\n",
    "task=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p')\n",
    "        task.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        task.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "68ba8330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Regression',\n",
       " 'Classification, Regression',\n",
       " 'Classification',\n",
       " 'Classification, Regression',\n",
       " 'Regression',\n",
       " 'Regression',\n",
       " 'Regression',\n",
       " 'Regression',\n",
       " 'Regression',\n",
       " 'Classification, Clustering',\n",
       " 'Classification',\n",
       " 'Regression',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification, Regression',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a0a60611",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Scrapping Dataset Attribute type\n",
    "att=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p')\n",
    "        att.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        att.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e869b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Real',\n",
       " 'Real',\n",
       " 'N/A',\n",
       " 'Integer, Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'N/A',\n",
       " 'Real',\n",
       " 'Integer, Real',\n",
       " 'Real',\n",
       " 'Categorical, Integer',\n",
       " 'Integer, Real',\n",
       " 'Integer, Real',\n",
       " 'Categorical, Integer, Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Real',\n",
       " 'Categorical',\n",
       " 'Integer, Real',\n",
       " 'Categorical, Integer, Real']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c384724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Dataset No of instances\n",
    "ins=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p')\n",
    "        ins.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        ins.append('-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "551e56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['107',\n",
       " '158716',\n",
       " '15744',\n",
       " '153000',\n",
       " '557',\n",
       " '557',\n",
       " '36',\n",
       " '731',\n",
       " '731',\n",
       " '4200',\n",
       " '61069',\n",
       " '52417',\n",
       " '150',\n",
       " '48842',\n",
       " '13611',\n",
       " '178',\n",
       " '303',\n",
       " '4898',\n",
       " '3810',\n",
       " '45211',\n",
       " '569',\n",
       " '1728',\n",
       " '900',\n",
       " '4177']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    " ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0f9592bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Dataset No of Attribute\n",
    "attno=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p')\n",
    "        attno.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        attno.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8338f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6',\n",
       " '4',\n",
       " 'N/A',\n",
       " '5',\n",
       " '5',\n",
       " '5',\n",
       " '15',\n",
       " '1068',\n",
       " '1068',\n",
       " '7',\n",
       " '21',\n",
       " '9',\n",
       " '4',\n",
       " '14',\n",
       " '17',\n",
       " '13',\n",
       " '75',\n",
       " '12',\n",
       " '8',\n",
       " '17',\n",
       " '32',\n",
       " '6',\n",
       " '8',\n",
       " '8']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " attno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f1e1d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Dataset date\n",
    "iyear=[]\n",
    "for i in product_URL:\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p')\n",
    "        iyear.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        iyear.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "33c10468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-06-05',\n",
       " '2021-05-25',\n",
       " '2021-05-18',\n",
       " '2021-05-02',\n",
       " '2021-04-21',\n",
       " '2021-04-21',\n",
       " '2021-04-20',\n",
       " '2021-04-20',\n",
       " '2021-04-20',\n",
       " '2021-04-14',\n",
       " '2021-04-11',\n",
       " '2021-04-03',\n",
       " '1988-07-01',\n",
       " '1996-05-01',\n",
       " '2020-09-14',\n",
       " '1991-07-01',\n",
       " '1988-07-01',\n",
       " '2009-10-07',\n",
       " '2019-10-06',\n",
       " '2012-02-14',\n",
       " '1995-11-01',\n",
       " '1997-06-01',\n",
       " '2021-04-01',\n",
       " '1995-12-01']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "58031856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instance</th>\n",
       "      <th>No of Attribute</th>\n",
       "      <th>Year</th>\n",
       "      <th>Dataset URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Average Localization Error (ALE) in sensor nod...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>107</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-06-05</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Averag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/9mers+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TamilSentiMix Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>15744</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/TamilS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accelerometer Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>153000</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Accele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synchronous Machine Data Set Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Synchr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Synchronous Machine Data Set Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Synchr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pedal Me Bicycle Deliveries Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Pedal+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Wikipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Wikipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkish Headlines Dataset Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4200</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Turkis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Secondary Mushroom Dataset Data Set</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>61069</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Power consumption of Tetouan city Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>52417</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-04-03</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Power+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Iris Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988-07-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Iris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996-05-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dry Bean Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Dry+Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991-07-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Wine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heart Disease Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>75</td>\n",
       "      <td>1988-07-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Heart+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wine Quality Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-10-07</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Wine+Q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rice (Cammeo and Osmancik) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Rice+%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank Marketing Data Set</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>45211</td>\n",
       "      <td>17</td>\n",
       "      <td>2012-02-14</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Bank+M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>1995-11-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Breast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Car Evaluation Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997-06-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Car+Ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Raisin Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Raisin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Abalone Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995-12-01</td>\n",
       "      <td>https://archive.ics.uci.edu/ml/datasets/Abalone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Dataset Name  \\\n",
       "0   Average Localization Error (ALE) in sensor nod...   \n",
       "1                         9mers from cullpdb Data Set   \n",
       "2                              TamilSentiMix Data Set   \n",
       "3                              Accelerometer Data Set   \n",
       "4               Synchronous Machine Data Set Data Set   \n",
       "5               Synchronous Machine Data Set Data Set   \n",
       "6                Pedal Me Bicycle Deliveries Data Set   \n",
       "7                  Wikipedia Math Essentials Data Set   \n",
       "8                  Wikipedia Math Essentials Data Set   \n",
       "9                  Turkish Headlines Dataset Data Set   \n",
       "10                Secondary Mushroom Dataset Data Set   \n",
       "11         Power consumption of Tetouan city Data Set   \n",
       "12                                      Iris Data Set   \n",
       "13                                     Adult Data Set   \n",
       "14                          Dry Bean Dataset Data Set   \n",
       "15                                      Wine Data Set   \n",
       "16                             Heart Disease Data Set   \n",
       "17                              Wine Quality Data Set   \n",
       "18                Rice (Cammeo and Osmancik) Data Set   \n",
       "19                            Bank Marketing Data Set   \n",
       "20      Breast Cancer Wisconsin (Diagnostic) Data Set   \n",
       "21                            Car Evaluation Data Set   \n",
       "22                            Raisin Dataset Data Set   \n",
       "23                                   Abalone Data Set   \n",
       "\n",
       "                    Data type                        Task  \\\n",
       "0                Multivariate                  Regression   \n",
       "1                  Sequential  Classification, Regression   \n",
       "2                         N/A              Classification   \n",
       "3                Multivariate  Classification, Regression   \n",
       "4                Multivariate                  Regression   \n",
       "5                Multivariate                  Regression   \n",
       "6                 Time-Series                  Regression   \n",
       "7                 Time-Series                  Regression   \n",
       "8                 Time-Series                  Regression   \n",
       "9                        Text  Classification, Clustering   \n",
       "10                 Univariate              Classification   \n",
       "11  Multivariate, Time-Series                  Regression   \n",
       "12               Multivariate              Classification   \n",
       "13               Multivariate              Classification   \n",
       "14               Multivariate              Classification   \n",
       "15               Multivariate              Classification   \n",
       "16               Multivariate              Classification   \n",
       "17               Multivariate  Classification, Regression   \n",
       "18               Multivariate              Classification   \n",
       "19                 Data Types              Classification   \n",
       "20               Multivariate              Classification   \n",
       "21               Multivariate              Classification   \n",
       "22               Multivariate              Classification   \n",
       "23               Multivariate              Classification   \n",
       "\n",
       "                Attribute Type No of Instance No of Attribute        Year  \\\n",
       "0                         Real            107               6  2021-06-05   \n",
       "1                         Real         158716               4  2021-05-25   \n",
       "2                          N/A          15744             N/A  2021-05-18   \n",
       "3                Integer, Real         153000               5  2021-05-02   \n",
       "4                         Real            557               5  2021-04-21   \n",
       "5                         Real            557               5  2021-04-21   \n",
       "6                         Real             36              15  2021-04-20   \n",
       "7                         Real            731            1068  2021-04-20   \n",
       "8                         Real            731            1068  2021-04-20   \n",
       "9                          N/A           4200               7  2021-04-14   \n",
       "10                        Real          61069              21  2021-04-11   \n",
       "11               Integer, Real          52417               9  2021-04-03   \n",
       "12                        Real            150               4  1988-07-01   \n",
       "13        Categorical, Integer          48842              14  1996-05-01   \n",
       "14               Integer, Real          13611              17  2020-09-14   \n",
       "15               Integer, Real            178              13  1991-07-01   \n",
       "16  Categorical, Integer, Real            303              75  1988-07-01   \n",
       "17                        Real           4898              12  2009-10-07   \n",
       "18                        Real           3810               8  2019-10-06   \n",
       "19                        Real          45211              17  2012-02-14   \n",
       "20                        Real            569              32  1995-11-01   \n",
       "21                 Categorical           1728               6  1997-06-01   \n",
       "22               Integer, Real            900               8  2021-04-01   \n",
       "23  Categorical, Integer, Real           4177               8  1995-12-01   \n",
       "\n",
       "                                          Dataset URL  \n",
       "0   https://archive.ics.uci.edu/ml/datasets/Averag...  \n",
       "1   https://archive.ics.uci.edu/ml/datasets/9mers+...  \n",
       "2   https://archive.ics.uci.edu/ml/datasets/TamilS...  \n",
       "3   https://archive.ics.uci.edu/ml/datasets/Accele...  \n",
       "4   https://archive.ics.uci.edu/ml/datasets/Synchr...  \n",
       "5   https://archive.ics.uci.edu/ml/datasets/Synchr...  \n",
       "6   https://archive.ics.uci.edu/ml/datasets/Pedal+...  \n",
       "7   https://archive.ics.uci.edu/ml/datasets/Wikipe...  \n",
       "8   https://archive.ics.uci.edu/ml/datasets/Wikipe...  \n",
       "9   https://archive.ics.uci.edu/ml/datasets/Turkis...  \n",
       "10  https://archive.ics.uci.edu/ml/datasets/Second...  \n",
       "11  https://archive.ics.uci.edu/ml/datasets/Power+...  \n",
       "12       https://archive.ics.uci.edu/ml/datasets/Iris  \n",
       "13      https://archive.ics.uci.edu/ml/datasets/Adult  \n",
       "14  https://archive.ics.uci.edu/ml/datasets/Dry+Be...  \n",
       "15       https://archive.ics.uci.edu/ml/datasets/Wine  \n",
       "16  https://archive.ics.uci.edu/ml/datasets/Heart+...  \n",
       "17  https://archive.ics.uci.edu/ml/datasets/Wine+Q...  \n",
       "18  https://archive.ics.uci.edu/ml/datasets/Rice+%...  \n",
       "19  https://archive.ics.uci.edu/ml/datasets/Bank+M...  \n",
       "20  https://archive.ics.uci.edu/ml/datasets/Breast...  \n",
       "21  https://archive.ics.uci.edu/ml/datasets/Car+Ev...  \n",
       "22  https://archive.ics.uci.edu/ml/datasets/Raisin...  \n",
       "23    https://archive.ics.uci.edu/ml/datasets/Abalone  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe \n",
    "\n",
    "DF=pd.DataFrame({'Dataset Name':dataname,'Data type':datatype,'Task':task,'Attribute Type':att,'No of Instance':ins,'No of Attribute':attno,'Year':iyear,'Dataset URL':product_URL})\n",
    "DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f0fc0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd7ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
